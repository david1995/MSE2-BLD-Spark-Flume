########## definitions
my_agent.sources = views purchases
my_agent.channels = all purchases
my_agent.sinks = all purchases


########## source properties
my_agent.sources.views.type = http
my_agent.sources.views.port = 28000
my_agent.sources.views.handler = org.apache.flume.source.http.JSONHandler

my_agent.sources.purchases.type = http
my_agent.sources.purchases.bind = 0.0.0.0
my_agent.sources.purchases.port = 28001


########## channel properties
my_agent.channels.all.type = memory
my_agent.channels.all.capacity = 10000
my_agent.channels.all.transactionCapacity = 100

my_agent.channels.purchases.type = memory
my_agent.channels.purchases.capacity = 10000
my_agent.channels.all.transactionCapacity = 100


########## sink properties
my_agent.sinks.purchases.type = logger

my_agent.sinks.all.type = file_roll
my_agent.sinks.all.sink.directory = /tmp
my_agent.sinks.all.sink.rollInterval = 10


########## bindings
my_agent.sources.views.channels = all
my_agent.sources.purchases.channels = all purchases
my_agent.sinks.all.channel = all
my_agent.sinks.purchases.channel = purchases









########### definitions
#my_agent.sources = real-time real-time-avro
#my_agent.channels = kafka s3
#my_agent.sinks = kafka s3
#
#
########### source properties
#my_agent.sources.real-time.type = http
#my_agent.sources.real-time.port = 28000
#my_agent.sources.real-time.channels = kafka s3
#my_agent.sources.real-time.handler = org.apache.flume.source.http.JSONHandler
#my_agent.sources.real-time.selector.type = multiplexing
#my_agent.sources.real-time.selector.header = event_sink
#my_agent.sources.real-time.selector.mapping.kafka = kafka
#my_agent.sources.real-time.selector.mapping.s3 = s3
#
#my_agent.sources.real-time-avro.type = avro
#my_agent.sources.real-time-avro.bind = 0.0.0.0
#my_agent.sources.real-time-avro.port = 28001
#my_agent.sources.real-time-avro.channels = kafka s3
#my_agent.sources.real-time-avro.selector.type = multiplexing
#my_agent.sources.real-time-avro.selector.header = event_sink
#my_agent.sources.real-time-avro.selector.mapping.kafka = kafka
#my_agent.sources.real-time-avro.selector.mapping.s3 = s3
#
#
########### channel properties
#my_agent.channels.kafka.type = memory
#my_agent.channels.kafka.capacity = 10000000
#my_agent.channels.kafka.transactionCapacity = 10000
#
#my_agent.channels.s3.type = memory
#my_agent.channels.s3.capacity = 10000000
#my_agent.channels.s3.transactionCapacity = 10000
#
#
########### sink properties
#my_agent.sinks.s3.type = null
##my_agent.sinks.s3.type = hdfs
##my_agent.sinks.s3.hdfs.rollInterval = 30
##my_agent.sinks.s3.hdfs.rollSize = 10240000
##my_agent.sinks.s3.hdfs.batchSize = 10000
###my_agent.sinks.s3.hdfs.path = s3n://AKIAJAWMBWNOT6KJMALQ:M5Nva68jxCA15RZ6BAJaf0ucKA0vBKsBMLAilj2+@mobfox-flume/%y-%m-%d/%H%M/%S
##my_agent.sinks.s3.hdfs.path = s3n://AKIAJXTWPYNFCC6GETEQ:tYgfaMKeT62idYFId0n9uDkuohUieMUrIcZZUvwi@mobfox-flume/real-time/%Y-%m-%d/%H%M
##my_agent.sinks.s3.hdfs.roundUnit = second
##my_agent.sinks.s3.hdfs.callTimeout = 10000
#
#my_agent.sinks.kafka.type = org.apache.flume.sink.kafka.KafkaSink
#my_agent.sinks.kafka.brokerList = 172.30.12.137:30000,172.30.9.142:30000,172.30.3.61:30000,172.30.13.134:3000,172.30.3.26:3000,172.30.15.49:3000
## only the default, you can set a custom topic through the 'topic' header
#my_agent.sinks.kafka.topic = real-time-all
#my_agent.sinks.kafka.batchSize = 100
#
#
########### bindings
#my_agent.sinks.kafka.channel = kafka
#my_agent.sinks.s3.channel = s3
#
#
#